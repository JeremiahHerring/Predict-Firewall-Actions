{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81fa18-1352-470b-ba12-0dcb2fb32316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b34b43-e119-4a9d-8f82-2490b72ac55b",
   "metadata": {},
   "source": [
    "Implement 1st ML Classifier: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ea4ee-8517-4616-b65c-d38d5894b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "internet_data = pd.read_csv('preprocessed_internet_data.csv')\n",
    "\n",
    "internet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ca058-3825-4d5c-b4c9-31dd21422d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e07c5-f41a-421f-b4c9-850eda7815dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = internet_data.drop('Action', axis=1)  \n",
    "y = internet_data['Action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2cdfc9-8148-4610-8c1e-a191c8709e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "nat_ports = internet_data['NAT Source Port']\n",
    "nat_ports\n",
    "\n",
    "target_variable = y \n",
    "\n",
    "relationship_df = pd.DataFrame({\n",
    "    'nat source port': nat_ports,\n",
    "    'Target': target_variable\n",
    "})\n",
    "\n",
    "relationship_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5808b280-fb6e-49e2-8aff-1e5722e20f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a1609-66c4-4d55-a8da-1bb335356d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54591ce7-7775-4632-baac-68c001b81ae7",
   "metadata": {},
   "source": [
    "1. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cddc73-5b83-4eda-b38b-782449909804",
   "metadata": {},
   "source": [
    "Let's first assess feature importance so we can figure out which features contribute the most to our model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e331033-3110-4d6b-9971-51b8ee2f86e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=2)\n",
    "\n",
    "# Stratified KFold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Store feature importances for each fold\n",
    "feature_importances = []\n",
    "\n",
    "cv_results = cross_validate(model, X, y, cv=skf, scoring=scoring, return_estimator=True)\n",
    "\n",
    "for estimator in cv_results['estimator']:\n",
    "    feature_importances.append(estimator.feature_importances_)\n",
    "\n",
    "# Calculate and display mean metrics\n",
    "mean_metrics = {key: np.mean(values) for key, values in cv_results.items() if key.startswith('test_')}\n",
    "print(\"Average Metrics across folds:\")\n",
    "for metric, value in mean_metrics.items():\n",
    "    print(f\"  {metric.replace('test_', '').capitalize()}: {value:.4f}\")\n",
    "\n",
    "# Convert the list of feature importances to a DataFrame for easier interpretation\n",
    "feature_importances = np.array(feature_importances)\n",
    "\n",
    "# Average the feature importances across folds\n",
    "mean_importances = feature_importances.mean(axis=0)\n",
    "\n",
    "# Create a DataFrame with feature names and their corresponding importances\n",
    "feature_names = X.columns  \n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': mean_importances\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(importance_df)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importances in Random Forest (Average across folds)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dde988-5db1-41f6-9fa7-948e925e79e4",
   "metadata": {},
   "source": [
    "Interpreting the feature importance graph, we see that the two most important features are NAT Source Port and Elapsed Time. Let's use random forest with a depth of 2 and a singular decision tree with a depth of 2 to test the accuracy of our model using these features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa13c7f8-f875-4c21-9751-35f9e92d5ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42)\n",
    "\n",
    "# Stratified KFold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Store metrics and confusion matrices for each fold\n",
    "tree_accuracies, rf_accuracies = [], []\n",
    "tree_conf_matrices, rf_conf_matrices = [], []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Split data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Train and predict with Decision Tree\n",
    "    tree_model.fit(X_train, y_train)\n",
    "    tree_preds = tree_model.predict(X_test)\n",
    "    tree_accuracies.append(accuracy_score(y_test, tree_preds))\n",
    "    tree_conf_matrices.append(confusion_matrix(y_test, tree_preds))\n",
    "\n",
    "    # Train and predict with Random Forest\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_preds = rf_model.predict(X_test)\n",
    "    rf_accuracies.append(accuracy_score(y_test, rf_preds))\n",
    "    rf_conf_matrices.append(confusion_matrix(y_test, rf_preds))\n",
    "\n",
    "# Average accuracies\n",
    "avg_tree_accuracy = np.mean(tree_accuracies)\n",
    "avg_rf_accuracy = np.mean(rf_accuracies)\n",
    "\n",
    "print(f\"Average Accuracy (Decision Tree, max_depth=2): {avg_tree_accuracy:.4f}\")\n",
    "print(f\"Average Accuracy (Random Forest, n_estimators=100, max_depth=2): {avg_rf_accuracy:.4f}\")\n",
    "\n",
    "# Visualize confusion matrices for the last fold\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ConfusionMatrixDisplay(tree_conf_matrices[-1], display_labels=tree_model.classes_).plot(ax=axes[0], cmap=\"Blues\")\n",
    "axes[0].set_title(\"Decision Tree Confusion Matrix (Last Fold)\")\n",
    "\n",
    "ConfusionMatrixDisplay(rf_conf_matrices[-1], display_labels=rf_model.classes_).plot(ax=axes[1], cmap=\"Blues\")\n",
    "axes[1].set_title(\"Random Forest Confusion Matrix (Last Fold)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ed47db-757d-4aa2-8605-327d1766df37",
   "metadata": {},
   "source": [
    "We see that there is not much of a difference between the accuracy of the single decision tree and random forest. We can consider using one decision tree for this data since it computationally inexpensive, especially with a depth of 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e441de81-8368-4e6b-8b04-5dfc673d143f",
   "metadata": {},
   "source": [
    "2. K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c4cf55-94ec-4ad8-90f4-bbc010e025ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Range of k values to test\n",
    "k_range = range(1, 21)  \n",
    "\n",
    "# Store the accuracy for each k\n",
    "knn_accuracies = []\n",
    "\n",
    "# Stratified K-Fold Cross-Validation for each k value\n",
    "for k in k_range:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    fold_accuracies = [] \n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        knn_model.fit(X_train, y_train)\n",
    "        knn_preds = knn_model.predict(X_test)\n",
    "\n",
    "        fold_accuracies.append(accuracy_score(y_test, knn_preds))\n",
    "\n",
    "    # Average accuracy for this value of k\n",
    "    knn_accuracies.append(np.mean(fold_accuracies))\n",
    "\n",
    "# Plot the elbow curve to find the best value for k\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(k_range, knn_accuracies, marker='o', color='b', linestyle='-', linewidth=2, markersize=8)\n",
    "plt.title('KNN Elbow Plot (Accuracy vs. k)', fontsize=14)\n",
    "plt.xlabel('Number of Neighbors (k)', fontsize=12)\n",
    "plt.ylabel('Average Accuracy', fontsize=12)\n",
    "plt.xticks(k_range)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d24db8-a92d-42e5-81f5-fc6ea74415d0",
   "metadata": {},
   "source": [
    "The highest accuracy for k looks to be 7, although all the values for k seem to be above 98%. We will stick with k = 7 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd40829-2139-449f-af42-9b51536605db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KNN model with 7 neighbors\n",
    "k_neighbors = 7\n",
    "knn_model = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
    "\n",
    "# Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "knn_accuracies = []\n",
    "knn_conf_matrices = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    knn_preds = knn_model.predict(X_test)\n",
    "\n",
    "    knn_accuracies.append(accuracy_score(y_test, knn_preds))\n",
    "    knn_conf_matrices.append(confusion_matrix(y_test, knn_preds))\n",
    "\n",
    "# Average accuracy\n",
    "avg_knn_accuracy = np.mean(knn_accuracies)\n",
    "\n",
    "print(f\"Average Accuracy (KNN, k={k_neighbors}): {avg_knn_accuracy:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "ConfusionMatrixDisplay(knn_conf_matrices[-1], display_labels=knn_model.classes_).plot(cmap=\"Blues\")\n",
    "plt.title(f\"KNN Confusion Matrix (Last Fold, k={k_neighbors})\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
